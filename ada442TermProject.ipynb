{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                             roc_curve, roc_auc_score, precision_recall_curve, confusion_matrix)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Data Loading and Missing Value Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path, sep=';')\n",
    "\n",
    "# Function to check for missing values\n",
    "def check_missing_values(data):\n",
    "    missing_values = data.isin(['unknown']).sum()\n",
    "    missing_values = missing_values[missing_values > 0]\n",
    "    print(\"Missing Values:\")\n",
    "    print(missing_values)\n",
    "    return data, missing_values\n",
    "\n",
    "# Function to calculate percentage of missing values\n",
    "def calculate_missing_percentage(data_missing):\n",
    "    data, missing_values = data_missing\n",
    "    missing_percentage = (missing_values / len(data)) * 100\n",
    "    print(\"\\nPercentage of Missing Values:\")\n",
    "    print(missing_percentage)\n",
    "    return data, missing_values, missing_percentage\n",
    "\n",
    "# Function to visualize missing values\n",
    "def visualize_missing_values(data_missing_percentage):\n",
    "    data, missing_values, missing_percentage = data_missing_percentage\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=missing_values.index, y=missing_values.values)\n",
    "    plt.title('Count of Missing Values by Column')\n",
    "    plt.ylabel('Count of Missing Values')\n",
    "    plt.xlabel('Columns')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "    return data\n",
    "\n",
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('load_data', FunctionTransformer(lambda _: load_data('dataset/bank-additional.csv'), validate=False)),\n",
    "    ('check_missing_values', FunctionTransformer(check_missing_values, validate=False)),\n",
    "    ('calculate_missing_percentage', FunctionTransformer(calculate_missing_percentage, validate=False)),\n",
    "    ('visualize_missing_values', FunctionTransformer(visualize_missing_values, validate=False))\n",
    "])\n",
    "\n",
    "data = pipeline.fit_transform(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1.1: Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to drop the 'duration' column because it is not known before a call is performed\n",
    "def drop_duration(data):\n",
    "    return data.drop('duration', axis=1)\n",
    "\n",
    "# Function to convert 'yes'/'no' target to binary\n",
    "def convert_target(data):\n",
    "    data['y'] = data['y'].map({'yes': 1, 'no': 0})\n",
    "    return data\n",
    "\n",
    "# Function to analyze missing values's impact and visualize\n",
    "def analyze_missing_values(data, missing_values):\n",
    "    fig, axes = plt.subplots(nrows=len(missing_values.index), ncols=1, figsize=(12, 8 * len(missing_values.index)))\n",
    "\n",
    "    for ax, col in zip(axes, missing_values.index):\n",
    "        missing_mask = data[col] == 'unknown'\n",
    "        total_missing = missing_mask.sum()\n",
    "        total_non_missing = len(data) - total_missing\n",
    "\n",
    "        print(f\"{col} (missing: {total_missing})\")\n",
    "        proportion = data.groupby(missing_mask)['y'].mean()\n",
    "        print(\"Proportion of 'yes' for missing vs non-missing:\")\n",
    "        print(f\"Missing: {proportion[True]:.2%}\")\n",
    "        print(f\"Non-missing: {proportion[False]:.2%}\")\n",
    "\n",
    "        # Calculate percentage difference\n",
    "        diff_percentage = (proportion[True] - proportion[False]) * 100\n",
    "        print(f\"Difference in proportion: {diff_percentage:.2f}%\")\n",
    "        print()\n",
    "\n",
    "        # Visualization with seaborn this time not with the matplotlib bcs yuksel hates it\n",
    "        sns.barplot(x=[f'Missing ({total_missing})', f'Non-missing ({total_non_missing})'], \n",
    "                    y=[proportion[True], proportion[False]], ax=ax)\n",
    "        ax.set_title(f'Proportion of \"yes\" for {col}')\n",
    "        ax.set_ylabel('Proportion of \"yes\"')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return data\n",
    "\n",
    "# Extract missing values\n",
    "_, missing_values = check_missing_values(data)\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('drop_duration', FunctionTransformer(drop_duration)),\n",
    "    ('convert_target', FunctionTransformer(convert_target)),\n",
    "    ('analyze_missing_values', FunctionTransformer(analyze_missing_values, kw_args={'missing_values': missing_values}))\n",
    "])\n",
    "\n",
    "data = pipeline.fit_transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| **Column**   | **Missing Count** | **Difference in Proportion of 'Yes'** | **Decision**                                                                                                                                          |\n",
    "|---------------|-------------------|---------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **job**       | 39               | -0.70%                                | The small difference suggests minimal bias. Imputed missing values with the mode (`most frequent value`).                                                  |\n",
    "| **marital**   | 11               | -1.86%                                | The difference is small but notable. Imputed missing values with the mode, as the missing rate and impact are low.                                         |\n",
    "| **education** | 167              | +4.81%                                | Missing values appear to show higher success rates. \"unknown\" will be encoded as a separate category to capture this distinction.                      |\n",
    "| **default**   | 803              | -6.02%                                | The larger difference and high missing rate suggest that encoding \"unknown\" as a separate category might better capture its relationship to the target.   |\n",
    "| **housing**   | 105              | -2.44%                                | The moderate difference suggests some potential bias. However after further testing with the full dataset (where the proportion is -%0.47), this bias appears to be a result of the random %10 selected more so than the actual impact of the class. Imputed missing values with the mode. |\n",
    "| **loan**      | 105              | -2.44%                                | Similar situation to **housing** with a proportion of -%0.47, imputed with the mode. *The similarity with housing has been noted for future reference*|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Final Encoding Decisions and Reasons\n",
    "\n",
    "| **Variable**     | **Encoding Decision**     | **Reason**                                                                 |\n",
    "|------------------|---------------------------|---------------------------------------------------------------------------|\n",
    "| **job**          | One-hot encoding           | \"job\" is a nominal categorical variable with distinct types; one-hot encoding prevents introducing any ordinal relationships. |\n",
    "| **marital**      | One-hot encoding           | \"marital\" is a categorical variable with distinct values and no natural order. One-hot encoding handles it appropriately. |\n",
    "| **education**    | One-hot encoding           | \"education\" includes \"unknown\" as its own category; one-hot encoding treats each category (including `unknown`) as a separate binary column. |\n",
    "| **default**      | One-hot encoding           | \"default\" is a binary categorical variable with \"no\" and \"yes\" values and additionally includes \"unknown\" as its own category, so one-hot encoding is appropriate. |\n",
    "| **housing**      | One-hot encoding           | \"housing\" is a binary categorical variable with \"no\" and \"yes\" values, and one-hot encoding works well here. |\n",
    "| **loan**         | One-hot encoding           | \"loan\" is also binary, with \"no\" and \"yes\" values, and one-hot encoding is suitable. |\n",
    "| **contact**      | One-hot encoding           | \"contact\" is a nominal categorical variable with distinct types (\"cellular\", \"telephone\"), making one-hot encoding ideal. |\n",
    "| **month**        | Cyclical encoding (sin/cos) | \"month\" is cyclical (e.g., December follows January), so sine and cosine transformations capture its cyclical nature. The complete lack of January and February, alongside the rarity of December has been noted.  |\n",
    "| **day_of_week**  | One-hot encoding           | \"day_of_week\" is a nominal categorical variable with distinct values (days of the week) and no inherent order, so one-hot encoding is suitable. The lack of inherent order is due to the nature of this variable relating to many different weeks as opposed to a one week period. |\n",
    "| **poutcome**     | One-hot encoding           | \"poutcome\" is categorical with distinct values (e.g., \"failure\", \"success\"), and one-hot encoding captures the separate categories. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_month_sin_cos(X):\n",
    "    month_map = {'mar': 3, 'apr': 4, 'may': 5, 'jun': 6, 'jul': 7, 'aug': 8,\n",
    "                 'sep': 9, 'oct': 10, 'nov': 11, 'dec': 12}\n",
    "    months = X[\"month\"]  \n",
    "    months = months.map(month_map).fillna(0)  \n",
    "    month_sin = np.sin(2 * np.pi * months / 12)\n",
    "    month_cos = np.cos(2 * np.pi * months / 12)\n",
    "    return pd.DataFrame({\"month_sin\": month_sin, \"month_cos\": month_cos})\n",
    "\n",
    "def month_feature_names_out(self, input_features): #this took way too long to figure out jesus christ\n",
    "    return [\"month_sin\", \"month_cos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_impute_cols = ['job', 'marital', 'housing', 'loan']\n",
    "categorical_pass_cols = ['education', 'default']\n",
    "\n",
    "onehot_cols = ['job', 'marital', 'default', 'housing', 'loan', 'contact', \n",
    "               'day_of_week', 'poutcome', 'education']\n",
    "numerical_cols = ['age', 'campaign', 'pdays', 'previous', 'emp.var.rate', \n",
    "                  'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']\n",
    "\n",
    "# TODO for much later, pdays is one stupid column\n",
    "# it has 999 as a value which is a placeholder for never contacted, this might be \n",
    "# a problem for the model, if so we need to handle this, but first testing the model\n",
    "#  without handling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_imputer = SimpleImputer(strategy='most_frequent', missing_values='unknown')\n",
    "month_transformer = FunctionTransformer(encode_month_sin_cos, validate=False, feature_names_out=month_feature_names_out)\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "scaler = StandardScaler()\n",
    "\n",
    "#Impute\n",
    "data[categorical_impute_cols] = mode_imputer.fit_transform(data[categorical_impute_cols])\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('month_encoding', month_transformer, ['month']), \n",
    "        ('onehot', onehot_encoder, onehot_cols),\n",
    "        ('scaling', scaler, numerical_cols)\n",
    "    ],\n",
    "    remainder='passthrough',  # Keeps other columns as is, keeping response variable, annoying cascading side effect, the y variable is renamed to remainder__y\n",
    ")\n",
    "\n",
    "\n",
    "transformed_data = preprocessor.fit_transform(data)\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=preprocessor.get_feature_names_out())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names with prefixes\n",
    "numerical_cols_prefixed = [f'scaling__{col}' for col in numerical_cols]\n",
    "\n",
    "numerical_corr = transformed_df[numerical_cols_prefixed].corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(numerical_corr, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix - Numerical Features\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Intended to drop highly correlated features for some reason it lowers the f1 score\n",
    "#transformed_df = transformed_df.drop(columns=['scaling__euribor3m', 'scaling__emp.var.rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_corr = transformed_df[numerical_cols_prefixed + ['remainder__y']].corr()['remainder__y'].drop('remainder__y')\n",
    "print(target_corr.sort_values(ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not much to do here, no value is too low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update onehot_cols with prefixed column names\n",
    "onehot_cols_prefixed = [col for col in transformed_df.columns if col.startswith('onehot__')]\n",
    "\n",
    "#TODO experiment with different thresholds instead of 0.01\n",
    "low_variance_cols = [col for col in onehot_cols_prefixed if transformed_df[col].var() < 0.01]\n",
    "print(\"Low variance columns:\", low_variance_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pointbiserialr\n",
    "\n",
    "for col in onehot_cols_prefixed:\n",
    "    corr, _ = pointbiserialr(transformed_df[col], transformed_df['remainder__y'])\n",
    "    print(f\"Correlation between {col} and y: {corr}\")\n",
    "\n",
    "#TODO print better, check for very low correlation to possibly remove some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "X = transformed_df.drop(columns=['remainder__y'])\n",
    "y = transformed_df['remainder__y']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Huge class imbalance, will utilize SMOTE and RandomUnderSampler to balance the classes to see if that helps\n",
    "print(y_train.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function for evaluation and visualization\n",
    "def evaluate_model(model, X_test, y_test, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "    # Metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"\\n{name} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    # ROC Curve\n",
    "    if y_prob is not None:\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        auc_score = roc_auc_score(y_test, y_prob)\n",
    "        plt.figure()\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc_score:.2f})')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'{name} ROC Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return f1\n",
    "\n",
    "# Training strategies: Standard, Oversampling, Undersampling\n",
    "sampling_strategies = {\n",
    "    \"Standard\": None,\n",
    "    \"Oversampling (SMOTE)\": SMOTE(random_state=42),\n",
    "    \"Undersampling\": RandomUnderSampler(random_state=42)\n",
    "}\n",
    "\n",
    "# Hyperparameter grids\n",
    "param_grids = {\n",
    "    \"LogisticRegression\": {\n",
    "        \"classifier__C\": [0.1, 1, 10],\n",
    "        \"classifier__penalty\": [\"l2\"],\n",
    "        \"classifier__solver\": [\"liblinear\", \"lbfgs\"],\n",
    "        \"classifier__max_iter\": [100, 200, 500]\n",
    "    },\n",
    "    \"RandomForestClassifier\": {\n",
    "        \"classifier__n_estimators\": [100, 300, 500],\n",
    "        \"classifier__max_depth\": [None, 10, 20],\n",
    "        \"classifier__min_samples_split\": [2, 5, 10],\n",
    "        \"classifier__min_samples_leaf\": [1, 2, 4]\n",
    "    },\n",
    "    \"DecisionTreeClassifier\": {\n",
    "        \"classifier__max_depth\": [None, 10, 20, 30],\n",
    "        \"classifier__min_samples_split\": [2, 5, 10],\n",
    "        \"classifier__min_samples_leaf\": [1, 2, 4]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Models to train\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(random_state=42),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(random_state=42, class_weight='balanced', n_jobs=-1),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_model = None\n",
    "best_f1_score = 0\n",
    "best_model_name = \"\"\n",
    "best_strategy = \"\"\n",
    "\n",
    "# Train and evaluate for each sampling strategy and model\n",
    "for strategy_name, sampler in sampling_strategies.items():\n",
    "    print(f\"\\n*** Training with {strategy_name} ***\")\n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\nTraining {model_name}...\")\n",
    "        \n",
    "        # Create pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('sampler', sampler), \n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        # Grid search for best hyperparameters\n",
    "        grid_search = GridSearchCV(pipeline, param_grids[model_name], cv=5, scoring='f1', n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Best model and parameters\n",
    "        best_params = grid_search.best_params_\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "        best_pipeline = grid_search.best_estimator_\n",
    "\n",
    "        # Evaluate and visualize\n",
    "        f1 = evaluate_model(best_pipeline, X_test, y_test, f\"{model_name} ({strategy_name})\")\n",
    "        \n",
    "        # Track best model\n",
    "        if f1 > best_f1_score:\n",
    "            best_f1_score = f1\n",
    "            best_model = best_pipeline\n",
    "            best_model_name = model_name\n",
    "            best_strategy = strategy_name\n",
    "\n",
    "# Print best model\n",
    "print(f\"\\nBest Model: {best_model_name} trained with {best_strategy}\")\n",
    "print(f\"Best F1 Score: {best_f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(best_model, 'model.pkl')\n",
    "joblib.dump(preprocessor, 'preprocessing_pipeline.pkl')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
